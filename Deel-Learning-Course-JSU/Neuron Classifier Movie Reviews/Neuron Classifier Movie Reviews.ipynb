{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sentiment Analysis with a Single Neuron Classifier",
   "id": "890b17a5c9379302"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Introduction",
   "id": "bfeebbd338901b6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this exercise, you'll build a **single neuron classifier** using PyTorch to perform sentiment analysis on movie reviews. The dataset consists of movie reviews categorized as either **positive** or **negative**. By training the model, you'll learn to classify reviews based on their text content.\n",
    "\n",
    "The relationship between input features (word counts) and the target sentiment is modeled using a **linear neuron**, and the task involves converting textual data into numerical features using the **bag-of-words representation**.\n",
    "\n",
    "The dataset can be downloaded from [here](https://ai.stanford.edu/~amaas/data/sentiment/).\n",
    "\n",
    "By the end of this exercise, you will:\n",
    "\n",
    "1. Understand how to preprocess text data for machine learning using *CountVectorizer*.\n",
    "2. Implement and train a binary classifier using a single neuron (*nn.Linear*).\n",
    "3. Evaluate model performance using metrics like accuracy, precision, recall, and specificity.\n",
    "4. Test the model on custom reviews to make predictions.\n",
    "\n",
    "This hands-on exercise demonstrates the power of linear classifiers and provides a strong foundation for understanding text classification problems."
   ],
   "id": "92161e526a98cef4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![Alt Text](./images/mr.png)",
   "id": "c030a60e84578ceb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing Libraries",
   "id": "a9a54c38e6323cc8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This cell imports the necessary libraries:\n",
    "\n",
    " - *torch* and *torch.nn*: For building and training the machine learning model.\n",
    " - *pandas*: For managing and manipulating the dataset in a tabular format.\n",
    " - *CountVectorizer*: Converts text data into numerical features using a bag-of-words representation.\n",
    " - *load_files*: Loads the IMDb movie review dataset from a directory structure."
   ],
   "id": "c4bfd239eb85a45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:34:34.317175Z",
     "start_time": "2024-12-12T19:34:24.215616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_files"
   ],
   "id": "3603ffd53dad80b2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading and Preparing the Dataset",
   "id": "aaad257133068f91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- *load_files*: Loads the IMDb dataset. Reviews labeled *pos* are positive, and those labeled *neg* are negative.\n",
    "- *pd.DataFrame*: Converts the dataset into a pandas DataFrame for easier processing.\n",
    "- *decode('utf-8')*: Decodes the text data from bytes to a readable string format.\n",
    "- **Sentiment Conversion**: Converts sentiment labels to floating-point values for compatibility with PyTorch."
   ],
   "id": "a77697ee7f9e4471"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:36:40.539969Z",
     "start_time": "2024-12-12T19:34:36.186676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the IMDb movie review dataset (download it if needed)\n",
    "dataset = load_files(\"./data/aclImdb_v1/aclImdb/train\", categories=[\"pos\", \"neg\"], shuffle=True, random_state=42)\n",
    "data, target = dataset.data, dataset.target\n",
    "\n",
    "# Convert data to a DataFrame for easier handling\n",
    "df = pd.DataFrame({\"review\": [doc.decode('utf-8') for doc in data], \"sentiment\": target})\n",
    "df[\"sentiment\"] = df[\"sentiment\"].astype(float)  # Convert sentiment to float for PyTorch"
   ],
   "id": "5ddce214d46c3719",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Splitting the Dataset",
   "id": "2a75dfc963849511"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- *sample(frac=0.8)*: Randomly selects 80% of the data for training.\n",
    "- **Validation Set**: The remaining 20% is used for validation."
   ],
   "id": "d61b849005c5eb4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:36:46.391702Z",
     "start_time": "2024-12-12T19:36:46.369047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = df.sample(frac=0.8, random_state=0)\n",
    "df_val = df.drop(index=df_train.index)"
   ],
   "id": "7dacfe454407a5b2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Converting Text to Numerical Features",
   "id": "d4fabf8b960d20a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- *CountVectorizer*: Converts text into a bag-of-words representation, retaining the 1000 most frequent words.\n",
    "- *fit_transform*: Fits the vectorizer on the training data and transforms it into a sparse matrix of word counts.\n",
    "- *transform*: Transforms the validation data using the fitted vectorizer."
   ],
   "id": "40e35ccc9be224f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:36:59.009319Z",
     "start_time": "2024-12-12T19:36:49.093348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv = CountVectorizer(max_features=1000, stop_words=\"english\")\n",
    "reviews_train = cv.fit_transform(df_train[\"review\"])\n",
    "reviews_val = cv.transform(df_val[\"review\"])"
   ],
   "id": "a1cf790785630780",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating Tensors",
   "id": "febee54bddabbed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- *X_train* and *X_val*: Convert the sparse matrices of word counts into dense tensors for PyTorch.\n",
    "- *y_train* and *y_val*: Convert the target sentiment values into tensors and reshape them to match the model's output format."
   ],
   "id": "65ee67f6e68065aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:36:59.173246Z",
     "start_time": "2024-12-12T19:36:59.009319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = torch.tensor(reviews_train.todense(), dtype=torch.float32)\n",
    "y_train = torch.tensor(df_train[\"sentiment\"].values, dtype=torch.float32).reshape((-1, 1))\n",
    "\n",
    "X_val = torch.tensor(reviews_val.todense(), dtype=torch.float32)\n",
    "y_val = torch.tensor(df_val[\"sentiment\"].values, dtype=torch.float32).reshape((-1, 1))"
   ],
   "id": "16b1addf2da38a6e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Defining the Model",
   "id": "b93e6df77ada1035"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- *nn.Linear(1000, 1)*: A single neuron with 1000 input features (word counts) and 1 output (sentiment score).\n",
    "- *BCEWithLogitsLoss*: Combines a Sigmoid activation with Binary Cross-Entropy loss for classification tasks.\n",
    "- *SGD*: Optimizer that updates the model's weights using stochastic gradient descent with a learning rate of 0.02."
   ],
   "id": "73cedf4034f8fd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:41:49.120185Z",
     "start_time": "2024-12-12T19:41:49.108730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = nn.Linear(1000, 1)\n",
    "loss_fn = nn.BCEWithLogitsLoss()  # Binary Cross Entropy with logits\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ],
   "id": "c3b31cfbd5002d16",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training the Model",
   "id": "56a63f21f77d6657"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **Training Loop**: Runs for 10,000 epochs, updating the model weights to minimize the loss.\n",
    "- *model.train()*: Puts the model in training mode.\n",
    "- **Gradient Descent**:\n",
    "    - Clears gradients (*optimizer.zero_grad()*).\n",
    "    - Computes predictions (*outputs*).\n",
    "    - Calculates the loss (*loss_fn*).\n",
    "    - Backpropagates the gradients (*loss.backward()*).\n",
    "    - Updates the weights (*optimizer.step()*).\n",
    "- **Progress Printing**: Displays the loss every 1000 epochs."
   ],
   "id": "8fde01cfb1c36aa7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:46:06.801830Z",
     "start_time": "2024-12-12T19:41:51.390182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "for epoch in range(20000):\n",
    "    # Training pass\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = loss_fn(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss every 1000 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ],
   "id": "655b62ab9733e3da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6949761509895325\n",
      "Epoch 1000, Loss: 0.48841580748558044\n",
      "Epoch 2000, Loss: 0.44055911898612976\n",
      "Epoch 3000, Loss: 0.41479140520095825\n",
      "Epoch 4000, Loss: 0.39772844314575195\n",
      "Epoch 5000, Loss: 0.3852979838848114\n",
      "Epoch 6000, Loss: 0.3757256269454956\n",
      "Epoch 7000, Loss: 0.36807674169540405\n",
      "Epoch 8000, Loss: 0.36179855465888977\n",
      "Epoch 9000, Loss: 0.3565382957458496\n",
      "Epoch 10000, Loss: 0.3520577847957611\n",
      "Epoch 11000, Loss: 0.3481898009777069\n",
      "Epoch 12000, Loss: 0.34481292963027954\n",
      "Epoch 13000, Loss: 0.341836541891098\n",
      "Epoch 14000, Loss: 0.3391915559768677\n",
      "Epoch 15000, Loss: 0.33682435750961304\n",
      "Epoch 16000, Loss: 0.33469244837760925\n",
      "Epoch 17000, Loss: 0.3327619731426239\n",
      "Epoch 18000, Loss: 0.33100515604019165\n",
      "Epoch 19000, Loss: 0.3293995261192322\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Defining the Evaluation Function",
   "id": "c7507d9b6384c5d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **Evaluation Mode**: Disables gradient computation (*torch.no_grad()*).\n",
    "- **Metrics**:\n",
    "    - **Accuracy**: Overall correctness.\n",
    "    - **Precision**: Fraction of correctly predicted positives.\n",
    "    - **Recall** (Sensitivity): Fraction of true positives detected.\n",
    "    - **Specificity**: Fraction of true negatives detected."
   ],
   "id": "9d47581a14d55609"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:46:06.813733Z",
     "start_time": "2024-12-12T19:46:06.801830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = torch.sigmoid(model(X)) > 0.5\n",
    "        accuracy = (y_pred == y).type(torch.float32).mean().item()\n",
    "        precision = (y_pred[y_pred == 1] == y[y_pred == 1]).type(torch.float32).mean().item()\n",
    "        recall = (y_pred[y == 1] == y[y == 1]).type(torch.float32).mean().item()\n",
    "        specificity = (y_pred[y == 0] == y[y == 0]).type(torch.float32).mean().item()\n",
    "\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
    "        print(f\"Specificity: {specificity:.4f}\")"
   ],
   "id": "a8c5b645b3608418",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluating and Testing the Model",
   "id": "1c49fd9e04321083"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Training and Validation Evaluation:\n",
    "    - Uses evaluate_model() to assess accuracy, precision, recall, and specificity on both datasets.\n",
    "- Custom Predictions:\n",
    "    - Predicts the sentiment of new, unseen reviews.\n",
    "    - Sentiment Classification:\n",
    "        1. \\> 0.5: Positive sentiment.\n",
    "        2. <= 0.5: Negative sentiment.\n",
    "        \n",
    "This section demonstrates how the model generalizes to unseen data and provides actionable insights."
   ],
   "id": "9b0319ed8333380b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "66c7cb506e81fa5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:46:06.847070Z",
     "start_time": "2024-12-12T19:46:06.813733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate on training data\n",
    "print(\"Evaluating on the training data:\")\n",
    "evaluate_model(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation data\n",
    "print(\"Evaluating on the validation data:\")\n",
    "evaluate_model(X_val, y_val)\n",
    "\n",
    "# Custom predictions\n",
    "custom_reviews = [\n",
    "    \"This movie was fantastic! The plot was engaging and the acting was great.\",\n",
    "    \"I really hated this movie. It was a waste of time and money.\",\n",
    "    \"The film was okay, but nothing special. It had some good moments.\"\n",
    "]\n",
    "\n",
    "custom_messages = cv.transform(custom_reviews)\n",
    "X_custom = torch.tensor(custom_messages.todense(), dtype=torch.float32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = torch.sigmoid(model(X_custom))\n",
    "    print(\"\\nCustom Predictions:\")\n",
    "    for review, pred in zip(custom_reviews, predictions):\n",
    "        sentiment = \"Positive\" if pred > 0.5 else \"Negative\"\n",
    "        print(f\"Review: {review}\\nPredicted Sentiment: {sentiment} (Score: {pred.item():.4f})\\n\")"
   ],
   "id": "62693a53183fdee2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on the training data:\n",
      "Accuracy: 0.8699\n",
      "Precision: 0.8602\n",
      "Recall (Sensitivity): 0.8853\n",
      "Specificity: 0.8543\n",
      "Evaluating on the validation data:\n",
      "Accuracy: 0.8578\n",
      "Precision: 0.8480\n",
      "Recall (Sensitivity): 0.8630\n",
      "Specificity: 0.8528\n",
      "\n",
      "Custom Predictions:\n",
      "Review: This movie was fantastic! The plot was engaging and the acting was great.\n",
      "Predicted Sentiment: Positive (Score: 0.6094)\n",
      "\n",
      "Review: I really hated this movie. It was a waste of time and money.\n",
      "Predicted Sentiment: Negative (Score: 0.2225)\n",
      "\n",
      "Review: The film was okay, but nothing special. It had some good moments.\n",
      "Predicted Sentiment: Positive (Score: 0.5199)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
