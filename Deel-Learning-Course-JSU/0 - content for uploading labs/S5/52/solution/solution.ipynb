{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T08:33:22.837393Z",
     "start_time": "2025-08-24T08:33:16.600357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df = pd.read_csv(\"../starter/SMSSpamCollection\",\n",
    "                 sep=\"\\t\",\n",
    "                 names=[\"type\", \"message\"])\n",
    "\n",
    "df[\"spam\"] = df[\"type\"] == \"spam\"\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "\n",
    "df_train = df.sample(frac=0.8, random_state=0)\n",
    "df_val = df.drop(index=df_train.index)\n",
    "\n",
    "cv = CountVectorizer(max_features=1000)\n",
    "messages_train = cv.fit_transform(df_train[\"message\"])\n",
    "messages_val = cv.transform(df_val[\"message\"])\n",
    "\n",
    "X_train = torch.tensor(messages_train.todense(), dtype=torch.float32)\n",
    "y_train = torch.tensor(df_train[\"spam\"].values, dtype=torch.float32)\\\n",
    "        .reshape((-1, 1))\n",
    "\n",
    "X_val = torch.tensor(messages_val.todense(), dtype=torch.float32)\n",
    "y_val = torch.tensor(df_val[\"spam\"].values, dtype=torch.float32)\\\n",
    "        .reshape((-1, 1))\n",
    "\n",
    "model = nn.Linear(1000, 1)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02)\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = loss_fn(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(loss)\n",
    "\n",
    "def evaluate_model(X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = nn.functional.sigmoid(model(X)) > 0.25\n",
    "        print(\"accuracy:\", (y_pred == y).type(torch.float32).mean())\n",
    "        print(\"sensitivity:\", (y_pred[y == 1] == y[y == 1]).type(torch.float32).mean())\n",
    "        print(\"specificity:\", (y_pred[y == 0] == y[y == 0]).type(torch.float32).mean())\n",
    "        print(\"precision:\", (y_pred[y_pred == 1] == y[y_pred == 1]).type(torch.float32).mean())\n",
    "\n",
    "print(\"Evaluating on the training data\")\n",
    "evaluate_model(X_train, y_train)\n",
    "\n",
    "print(\"Evaluating on the validation data\")\n",
    "evaluate_model(X_val, y_val)\n",
    "\n",
    "# Transform the following custom messages with the fitted vectorizer:\n",
    "#   [\"We have release a new product, do you want to buy it?\",\n",
    "#    \"Winner! Great deal, call us to get this product for free\",\n",
    "#    \"Tomorrow is my birthday, do you come to the party?\"]\n",
    "# Create X_custom from cv.transform(...)\n",
    "# Run model on X_custom with sigmoid and print the predictions\n",
    "custom_messages = cv.transform([\n",
    "    \"We have release a new product, do you want to buy it?\",\n",
    "    \"Winner! Great deal, call us to get this product for free\",\n",
    "    \"Tomorrow is my birthday, do you come to the party?\"\n",
    "])\n",
    "\n",
    "X_custom = torch.tensor(custom_messages.todense(), dtype=torch.float32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = nn.functional.sigmoid(model(X_custom))\n",
    "    print(pred)"
   ],
   "id": "d2229f7a80453f1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6845, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.2238, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1637, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1364, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1202, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1093, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1013, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0950, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0900, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0858, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Evaluating on the training data\n",
      "accuracy: tensor(0.9789)\n",
      "sensitivity: tensor(0.9194)\n",
      "specificity: tensor(0.9883)\n",
      "precision: tensor(0.9255)\n",
      "Evaluating on the validation data\n",
      "accuracy: tensor(0.9740)\n",
      "sensitivity: tensor(0.9137)\n",
      "specificity: tensor(0.9826)\n",
      "precision: tensor(0.8819)\n",
      "tensor([[0.0520],\n",
      "        [0.6090],\n",
      "        [0.0129]])\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
