{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T09:56:09.811586Z",
     "start_time": "2025-08-24T09:52:49.028779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from transformers import BartTokenizer, BartModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv(\"../starter/SMSSpamCollection\",\n",
    "                 sep=\"\\t\",\n",
    "                 names=[\"type\", \"message\"])\n",
    "\n",
    "df[\"spam\"] = df[\"type\"] == \"spam\"\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "\n",
    "df_train = df.sample(frac=0.8, random_state=0)\n",
    "df_val = df.drop(index=df_train.index)\n",
    "\n",
    "# Replace CountVectorizer with BART embeddings.\n",
    "# - Import BartTokenizer, BartModel and tqdm.\n",
    "# - Initialize tokenizer/model: \"facebook/bart-base\".\n",
    "# - Write convert_to_embeddings(messages) that mean-pools last_hidden_state.\n",
    "# - Use it to build X_train and X_val from df_train/df_val messages.\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "bart_model = BartModel.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "def convert_to_embeddings(messages):\n",
    "    embeddings_list = []\n",
    "    for message in tqdm(messages):\n",
    "        out = tokenizer([message],\n",
    "                        padding=True,\n",
    "                        max_length=512,\n",
    "                        truncation=True,\n",
    "                        return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            bart_model.eval()\n",
    "            pred = bart_model(\n",
    "                input_ids=out[\"input_ids\"],\n",
    "                attention_mask=out[\"attention_mask\"]\n",
    "            )\n",
    "            vec = pred.last_hidden_state.mean(dim=1).reshape((-1))\n",
    "            embeddings_list.append(vec)\n",
    "    return torch.stack(embeddings_list)\n",
    "\n",
    "X_train = convert_to_embeddings(df_train[\"message\"].tolist())\n",
    "X_val   = convert_to_embeddings(df_val[\"message\"].tolist())\n",
    "\n",
    "y_train = torch.tensor(df_train[\"spam\"].values, dtype=torch.float32)\\\n",
    "        .reshape((-1, 1))\n",
    "y_val = torch.tensor(df_val[\"spam\"].values, dtype=torch.float32)\\\n",
    "        .reshape((-1, 1))\n",
    "\n",
    "# Change the Linear input dimension to 768 (BART hidden size).\n",
    "model = nn.Linear(768, 1)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02)\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = loss_fn(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(loss)\n",
    "\n",
    "def evaluate_model(X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = nn.functional.sigmoid(model(X)) > 0.25\n",
    "        print(\"accuracy:\", (y_pred == y)\\\n",
    "            .type(torch.float32).mean())\n",
    "\n",
    "        print(\"sensitivity:\", (y_pred[y == 1] == y[y == 1])\\\n",
    "            .type(torch.float32).mean())\n",
    "\n",
    "        print(\"specificity:\", (y_pred[y == 0] == y[y == 0])\\\n",
    "            .type(torch.float32).mean())\n",
    "\n",
    "        print(\"precision:\", (y_pred[y_pred == 1] == y[y_pred == 1])\\\n",
    "            .type(torch.float32).mean())\n",
    "\n",
    "print(\"Evaluating on the training data\")\n",
    "evaluate_model(X_train, y_train)\n",
    "\n",
    "print(\"Evaluating on the validation data\")\n",
    "evaluate_model(X_val, y_val)\n",
    "\n",
    "# For custom testing, use convert_to_embeddings on these texts\n",
    "# instead of cv.transform(...), then run the model and print probs.\n",
    "custom_messages = [\n",
    "    \"We have release a new product. Be sure to buy it now, we got a great deal!\",\n",
    "    \"Winner! Great deal, call us to get this product for free\",\n",
    "    \"Tomorrow is my birthday, do you come to the party?\"\n",
    "]\n",
    "X_custom = convert_to_embeddings(custom_messages)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = nn.functional.sigmoid(model(X_custom))\n",
    "    print(pred)"
   ],
   "id": "d2229f7a80453f1c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4458/4458 [02:38<00:00, 28.07it/s]\n",
      "100%|██████████| 1114/1114 [00:38<00:00, 28.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5472, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0269, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0200, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0164, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0141, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0124, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0111, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0101, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0092, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0085, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Evaluating on the training data\n",
      "accuracy: tensor(0.9984)\n",
      "sensitivity: tensor(0.9984)\n",
      "specificity: tensor(0.9984)\n",
      "precision: tensor(0.9902)\n",
      "Evaluating on the validation data\n",
      "accuracy: tensor(0.9946)\n",
      "sensitivity: tensor(0.9856)\n",
      "specificity: tensor(0.9959)\n",
      "precision: tensor(0.9716)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 30.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.1550e-01],\n",
      "        [8.4741e-01],\n",
      "        [4.2826e-07]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
