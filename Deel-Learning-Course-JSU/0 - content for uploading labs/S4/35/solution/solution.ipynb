{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:38:56.578199Z",
     "start_time": "2025-08-22T18:38:54.771876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Pandas: Reading the data\n",
    "df = pd.read_csv(\"../starter/used_cars.csv\")\n",
    "\n",
    "# Pandas: Preparing the data\n",
    "age = df[\"model_year\"].max() - df[\"model_year\"]\n",
    "\n",
    "milage = df[\"milage\"]\n",
    "milage = milage.str.replace(\",\", \"\")\n",
    "milage = milage.str.replace(\" mi.\", \"\")\n",
    "milage = milage.astype(int)\n",
    "\n",
    "price = df[\"price\"]\n",
    "price = price.str.replace(\"$\", \"\")\n",
    "price = price.str.replace(\",\", \"\")\n",
    "price = price.astype(int)\n",
    "\n",
    "# Torch: Creating X and y data (as tensors)\n",
    "X = torch.column_stack([\n",
    "    torch.tensor(age, dtype=torch.float32),\n",
    "    torch.tensor(milage, dtype=torch.float32)\n",
    "])\n",
    "\n",
    "# Compute X_mean and X_std (per-column), then normalize X using (X - X_mean) / X_std\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X = (X - X_mean) / X_std\n",
    "\n",
    "y = torch.tensor(price, dtype=torch.float32).reshape((-1, 1))\n",
    "y_mean = y.mean()\n",
    "y_std = y.std()\n",
    "y = (y - y_mean) / y_std\n",
    "# sys.exit()\n",
    "\n",
    "model = nn.Linear(2, 1)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Change learning rate to 0.001 and train for 10000 iterations\n",
    "# Inside the loop, print the loss every 100 iterations\n",
    "for i in range(0, 10000):\n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = loss_fn(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(loss)\n",
    "    # if i % 100 == 0:\n",
    "    #     print(model.bias)\n",
    "    #     print(model.weight)\n",
    "\n",
    "# Create X_data tensor with rows [[5, 10000], [2, 10000], [5, 20000]]\n",
    "X_data = torch.tensor([\n",
    "    [5, 10000],\n",
    "    [2, 10000],\n",
    "    [5, 20000]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Normalize X_data using the same X_mean and X_std as above\n",
    "X_data_norm = (X_data - X_mean) / X_std\n",
    "\n",
    "# Predict on normalized X_data, then de-normalize predictions with y_std and y_mean and print them\n",
    "prediction = model(X_data_norm)\n",
    "print(prediction * y_std + y_mean)"
   ],
   "id": "4879496a5f7224e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4260, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2919, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2030, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1413, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0965, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0628, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0365, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0155, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9985, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9845, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9728, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9629, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9476, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9416, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9366, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9322, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9082, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9079, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9077, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9075, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9073, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9071, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9070, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9069, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9068, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9067, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9067, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9066, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9065, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9065, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9065, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9064, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9064, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9064, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9064, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<MseLossBackward0>)\n",
      "tensor([[69600.0625],\n",
      "        [70284.9219],\n",
      "        [65167.9492]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
