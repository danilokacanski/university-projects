{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loan Aoorival Classification",
   "id": "d13c27592c6f0d6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:39:45.056738Z",
     "start_time": "2024-12-20T16:39:45.045888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd"
   ],
   "id": "505d05e12e19fcfb",
   "outputs": [],
   "execution_count": 194
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1st Option 81 --> 83.5 Accuracy",
   "id": "f1a4e78c023c8fca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:39:49.628897Z",
     "start_time": "2024-12-20T16:39:49.497622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"data/loan_data.csv\")\n",
    "df = df[[\"loan_status\", \"person_income\", \"loan_intent\", \"loan_percent_income\", \"credit_score\"]]\n",
    "df = pd.get_dummies(df, columns=[\"loan_intent\"])"
   ],
   "id": "baa5177165e81e03",
   "outputs": [],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:39:52.243435Z",
     "start_time": "2024-12-20T16:39:52.216955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = torch.tensor(df[\"loan_status\"], dtype=torch.float32)\\\n",
    "    .reshape((-1, 1))\n",
    "\n",
    "X_data = df.drop(\"loan_status\", axis=1).astype('float32').values\n",
    "X = torch.tensor(X_data, dtype=torch.float32)"
   ],
   "id": "4491c28a6b9143c",
   "outputs": [],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:39:53.978050Z",
     "start_time": "2024-12-20T16:39:53.960249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X = (X - X_mean) / X_std"
   ],
   "id": "31cb1afb93a9341e",
   "outputs": [],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:39:56.710028Z",
     "start_time": "2024-12-20T16:39:56.698229Z"
    }
   },
   "cell_type": "code",
   "source": "X_mean",
   "id": "f12d829aeab6c3f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.0319e+04, 1.3972e-01, 6.3261e+02, 1.5878e-01, 2.0340e-01, 1.0629e-01,\n",
       "        1.8996e-01, 1.6782e-01, 1.7376e-01])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:45:00.550716Z",
     "start_time": "2024-12-20T16:45:00.540285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# New one just little bit complex arhitecture \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(9, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 1)\n",
    ")"
   ],
   "id": "aebc66827107b8eb",
   "outputs": [],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:44:04.385099Z",
     "start_time": "2024-12-20T16:44:04.374625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This one is good you already showed them this\n",
    "model = nn.Linear(9,1)"
   ],
   "id": "11dcd044c8feb8d5",
   "outputs": [],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:45:03.550638Z",
     "start_time": "2024-12-20T16:45:03.541232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0015)"
   ],
   "id": "e043dc90fcae192d",
   "outputs": [],
   "execution_count": 209
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-20T16:46:25.701291Z",
     "start_time": "2024-12-20T16:45:06.072740Z"
    }
   },
   "source": [
    "num_entries = X.size(0)\n",
    "batch_size = 128    # This need to be higher because your testing is done with whole data so 32 is making big priblem here 128  is the optimal one\n",
    "\n",
    "for i in range(0, 100):  # Train longer for just neuron it converges after 10 epochs but NN doesnt\n",
    "    loss_sum = 0\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    loss = 0\n",
    "    train_total = 0\n",
    "    for start in range(0, num_entries, batch_size):\n",
    "        end = min(num_entries, start + batch_size)\n",
    "        X_data = X[start:end]\n",
    "        y_data = y[start:end]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(X_data)\n",
    "        y_pred = nn.functional.sigmoid(outputs) > 0.5\n",
    "        train_total += X_data.size(0)\n",
    "        train_correct += (y_pred == y_data).sum().item()\n",
    "        \n",
    "        loss = loss_fn(outputs, y_data)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    print(f'Loss = {loss}, training accuracy = {train_accuracy}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X)\n",
    "    y_pred = nn.functional.sigmoid(outputs) > 0.5\n",
    "    y_pred_correct = y_pred.type(torch.float32) == y\n",
    "    print(y_pred_correct.type(torch.float32).mean())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.8985163569450378, training accuracy = 79.88444444444444\n",
      "Loss = 1.1477254629135132, training accuracy = 80.54888888888888\n",
      "Loss = 1.1144108772277832, training accuracy = 81.21555555555555\n",
      "Loss = 1.1464998722076416, training accuracy = 81.36222222222223\n",
      "Loss = 1.1385337114334106, training accuracy = 81.44666666666667\n",
      "Loss = 1.148940086364746, training accuracy = 81.50888888888889\n",
      "Loss = 1.1529324054718018, training accuracy = 81.56\n",
      "Loss = 1.1600452661514282, training accuracy = 81.6\n",
      "Loss = 1.1665087938308716, training accuracy = 81.62666666666667\n",
      "Loss = 1.170323371887207, training accuracy = 81.64888888888889\n",
      "Loss = 1.175478458404541, training accuracy = 81.70222222222222\n",
      "Loss = 1.1779855489730835, training accuracy = 81.72444444444444\n",
      "Loss = 1.1805107593536377, training accuracy = 81.73555555555555\n",
      "Loss = 1.1777472496032715, training accuracy = 81.73333333333333\n",
      "Loss = 1.176803469657898, training accuracy = 81.77777777777777\n",
      "Loss = 1.1664354801177979, training accuracy = 81.85333333333334\n",
      "Loss = 1.1589815616607666, training accuracy = 81.90444444444445\n",
      "Loss = 1.1488804817199707, training accuracy = 81.95333333333333\n",
      "Loss = 1.1435778141021729, training accuracy = 82.0\n",
      "Loss = 1.1420512199401855, training accuracy = 82.05111111111111\n",
      "Loss = 1.2404531240463257, training accuracy = 81.59333333333333\n",
      "Loss = 1.109891653060913, training accuracy = 81.94888888888889\n",
      "Loss = 1.10914945602417, training accuracy = 82.03777777777778\n",
      "Loss = 1.092248558998108, training accuracy = 82.11333333333333\n",
      "Loss = 1.1018059253692627, training accuracy = 82.1288888888889\n",
      "Loss = 1.1050574779510498, training accuracy = 82.1\n",
      "Loss = 1.099942684173584, training accuracy = 82.2688888888889\n",
      "Loss = 1.0968884229660034, training accuracy = 82.32\n",
      "Loss = 1.0968008041381836, training accuracy = 82.35333333333334\n",
      "Loss = 1.098874568939209, training accuracy = 82.39111111111112\n",
      "Loss = 1.1055725812911987, training accuracy = 82.36888888888889\n",
      "Loss = 1.111545443534851, training accuracy = 82.43555555555555\n",
      "Loss = 1.116062879562378, training accuracy = 82.50666666666666\n",
      "Loss = 1.1224384307861328, training accuracy = 82.5111111111111\n",
      "Loss = 1.1296849250793457, training accuracy = 82.53111111111112\n",
      "Loss = 1.1299302577972412, training accuracy = 82.55111111111111\n",
      "Loss = 1.144660472869873, training accuracy = 82.22\n",
      "Loss = 1.1340813636779785, training accuracy = 82.46222222222222\n",
      "Loss = 1.136398434638977, training accuracy = 82.52666666666667\n",
      "Loss = 1.1397088766098022, training accuracy = 82.56888888888889\n",
      "Loss = 1.1405720710754395, training accuracy = 82.58\n",
      "Loss = 1.166858434677124, training accuracy = 82.18444444444444\n",
      "Loss = 1.1436800956726074, training accuracy = 82.43111111111111\n",
      "Loss = 1.1436645984649658, training accuracy = 82.48444444444445\n",
      "Loss = 1.1436238288879395, training accuracy = 82.52666666666667\n",
      "Loss = 1.1410880088806152, training accuracy = 82.50444444444445\n",
      "Loss = 1.1439837217330933, training accuracy = 82.56\n",
      "Loss = 1.144899606704712, training accuracy = 82.61111111111111\n",
      "Loss = 1.1454923152923584, training accuracy = 82.64222222222222\n",
      "Loss = 1.1428248882293701, training accuracy = 82.63333333333334\n",
      "Loss = 1.14380943775177, training accuracy = 82.66666666666667\n",
      "Loss = 1.1434327363967896, training accuracy = 82.7\n",
      "Loss = 1.1430797576904297, training accuracy = 82.70222222222222\n",
      "Loss = 1.1413031816482544, training accuracy = 82.72444444444444\n",
      "Loss = 1.1412180662155151, training accuracy = 82.72666666666667\n",
      "Loss = 1.1397285461425781, training accuracy = 82.73555555555555\n",
      "Loss = 1.1398556232452393, training accuracy = 82.74444444444444\n",
      "Loss = 1.14063560962677, training accuracy = 82.74888888888889\n",
      "Loss = 1.1402945518493652, training accuracy = 82.75555555555556\n",
      "Loss = 1.140167474746704, training accuracy = 82.76444444444445\n",
      "Loss = 1.1399928331375122, training accuracy = 82.7911111111111\n",
      "Loss = 1.1405099630355835, training accuracy = 82.8\n",
      "Loss = 1.1413639783859253, training accuracy = 82.82222222222222\n",
      "Loss = 1.1415044069290161, training accuracy = 82.80222222222223\n",
      "Loss = 1.1404623985290527, training accuracy = 82.82444444444444\n",
      "Loss = 1.1368482112884521, training accuracy = 82.80222222222223\n",
      "Loss = 1.1383557319641113, training accuracy = 82.81777777777778\n",
      "Loss = 1.1378154754638672, training accuracy = 82.84666666666666\n",
      "Loss = 1.136886477470398, training accuracy = 82.86\n",
      "Loss = 1.138822078704834, training accuracy = 82.85555555555555\n",
      "Loss = 1.1391831636428833, training accuracy = 82.88444444444444\n",
      "Loss = 1.1390279531478882, training accuracy = 82.87777777777778\n",
      "Loss = 1.1392500400543213, training accuracy = 82.87555555555555\n",
      "Loss = 1.1390804052352905, training accuracy = 82.87777777777778\n",
      "Loss = 1.1400856971740723, training accuracy = 82.89555555555556\n",
      "Loss = 1.1394518613815308, training accuracy = 82.9088888888889\n",
      "Loss = 1.1389591693878174, training accuracy = 82.94222222222223\n",
      "Loss = 1.1391366720199585, training accuracy = 82.95111111111112\n",
      "Loss = 1.139090657234192, training accuracy = 82.98222222222222\n",
      "Loss = 1.138269305229187, training accuracy = 82.97777777777777\n",
      "Loss = 1.138892650604248, training accuracy = 83.01333333333334\n",
      "Loss = 1.1388723850250244, training accuracy = 83.0\n",
      "Loss = 1.1399205923080444, training accuracy = 83.03111111111112\n",
      "Loss = 1.137789011001587, training accuracy = 83.01777777777778\n",
      "Loss = 1.137411117553711, training accuracy = 83.04444444444445\n",
      "Loss = 1.1388840675354004, training accuracy = 83.03111111111112\n",
      "Loss = 1.1371617317199707, training accuracy = 83.06888888888889\n",
      "Loss = 1.138020396232605, training accuracy = 83.02444444444444\n",
      "Loss = 1.1369385719299316, training accuracy = 83.01333333333334\n",
      "Loss = 1.1370593309402466, training accuracy = 83.04222222222222\n",
      "Loss = 1.1376508474349976, training accuracy = 83.03555555555556\n",
      "Loss = 1.137134313583374, training accuracy = 83.02444444444444\n",
      "Loss = 1.1412944793701172, training accuracy = 83.04444444444445\n",
      "Loss = 1.1391078233718872, training accuracy = 83.08444444444444\n",
      "Loss = 1.1402149200439453, training accuracy = 83.07111111111111\n",
      "Loss = 1.140523076057434, training accuracy = 83.0911111111111\n",
      "Loss = 1.1403510570526123, training accuracy = 83.08\n",
      "Loss = 1.1410924196243286, training accuracy = 83.08666666666667\n",
      "Loss = 1.139208197593689, training accuracy = 83.09777777777778\n",
      "Loss = 1.1399962902069092, training accuracy = 83.11111111111111\n",
      "tensor(0.8334)\n"
     ]
    }
   ],
   "execution_count": 210
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2nd Option 89.5 Neuron --> 93 NN Accuracy All of the Features",
   "id": "47f10a537b0b7958"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:49:06.138277Z",
     "start_time": "2024-12-20T16:49:05.977168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"data/loan_data.csv\")\n",
    "df = pd.get_dummies(df)"
   ],
   "id": "48ed444bd38bda92",
   "outputs": [],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:49:07.743196Z",
     "start_time": "2024-12-20T16:49:07.707446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = torch.tensor(df[\"loan_status\"], dtype=torch.float32) \\\n",
    "    .reshape((-1, 1))\n",
    "\n",
    "X_data = df.drop(\"loan_status\", axis=1).astype('float32').values\n",
    "X = torch.tensor(X_data, dtype=torch.float32)"
   ],
   "id": "52f8c435ee694711",
   "outputs": [],
   "execution_count": 212
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:49:09.516355Z",
     "start_time": "2024-12-20T16:49:09.483934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X = (X - X_mean) / X_std\n",
    "X_mean"
   ],
   "id": "faff05a155c137bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7764e+01, 8.0319e+04, 5.4103e+00, 9.5832e+03, 1.1007e+01, 1.3972e-01,\n",
       "        5.8675e+00, 6.3261e+02, 4.4798e-01, 5.5202e-01, 2.6729e-01, 2.9776e-01,\n",
       "        1.3800e-02, 2.6604e-01, 1.5511e-01, 4.1087e-01, 2.6000e-03, 6.5578e-02,\n",
       "        5.2096e-01, 1.5878e-01, 2.0340e-01, 1.0629e-01, 1.8996e-01, 1.6782e-01,\n",
       "        1.7376e-01, 4.9204e-01, 5.0796e-01])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:50:16.197769Z",
     "start_time": "2024-12-20T16:50:16.187684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(27, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 1)\n",
    ")"
   ],
   "id": "23a5c419e888876",
   "outputs": [],
   "execution_count": 217
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:49:12.016465Z",
     "start_time": "2024-12-20T16:49:12.005527Z"
    }
   },
   "cell_type": "code",
   "source": "model = nn.Linear(27, 1)",
   "id": "b58ae002b8f7d0af",
   "outputs": [],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:50:18.091126Z",
     "start_time": "2024-12-20T16:50:18.083420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0015)"
   ],
   "id": "2e8c98cfc9603b11",
   "outputs": [],
   "execution_count": 218
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T16:51:41.735716Z",
     "start_time": "2024-12-20T16:50:20.841290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_entries = X.size(0)\n",
    "batch_size = 128  # This need to be higher because your testing is done with whole data so 32 is making big priblem here 128  is the optimal one\n",
    "\n",
    "for i in range(0, 100):  # Train longer for just neuron it converges after 10 epochs but NN doesnt\n",
    "    loss_sum = 0\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    loss = 0\n",
    "    train_total = 0\n",
    "    for start in range(0, num_entries, batch_size):\n",
    "        end = min(num_entries, start + batch_size)\n",
    "        X_data = X[start:end]\n",
    "        y_data = y[start:end]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(X_data)\n",
    "        y_pred = nn.functional.sigmoid(outputs) > 0.5\n",
    "        train_total += X_data.size(0)\n",
    "        train_correct += (y_pred == y_data).sum().item()\n",
    "\n",
    "        loss = loss_fn(outputs, y_data)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    print(f'Loss = {loss}, training accuracy = {train_accuracy}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X)\n",
    "    y_pred = nn.functional.sigmoid(outputs) > 0.5\n",
    "    y_pred_correct = y_pred.type(torch.float32) == y\n",
    "    print(y_pred_correct.type(torch.float32).mean())"
   ],
   "id": "8d7da20bc97efaeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.06821276247501373, training accuracy = 86.88666666666667\n",
      "Loss = 0.2809129059314728, training accuracy = 88.83777777777777\n",
      "Loss = 0.2954653203487396, training accuracy = 89.42222222222222\n",
      "Loss = 0.29246652126312256, training accuracy = 89.8\n",
      "Loss = 0.29282453656196594, training accuracy = 90.13333333333334\n",
      "Loss = 0.2937873899936676, training accuracy = 90.38444444444444\n",
      "Loss = 0.2965458035469055, training accuracy = 90.56444444444445\n",
      "Loss = 0.29556164145469666, training accuracy = 90.77111111111111\n",
      "Loss = 0.29820573329925537, training accuracy = 90.88444444444444\n",
      "Loss = 0.29744836688041687, training accuracy = 90.97777777777777\n",
      "Loss = 0.29604560136795044, training accuracy = 91.13555555555556\n",
      "Loss = 0.29681262373924255, training accuracy = 91.25555555555556\n",
      "Loss = 0.2970195412635803, training accuracy = 91.28888888888889\n",
      "Loss = 0.29752710461616516, training accuracy = 91.32444444444444\n",
      "Loss = 0.3028034269809723, training accuracy = 91.3488888888889\n",
      "Loss = 0.3042839467525482, training accuracy = 91.43333333333334\n",
      "Loss = 0.30660560727119446, training accuracy = 91.47777777777777\n",
      "Loss = 0.30884605646133423, training accuracy = 91.55777777777777\n",
      "Loss = 0.3129536509513855, training accuracy = 91.62666666666667\n",
      "Loss = 0.31495773792266846, training accuracy = 91.66444444444444\n",
      "Loss = 0.3190094530582428, training accuracy = 91.7311111111111\n",
      "Loss = 0.3210437297821045, training accuracy = 91.76444444444445\n",
      "Loss = 0.324171245098114, training accuracy = 91.81111111111112\n",
      "Loss = 0.3253719210624695, training accuracy = 91.85555555555555\n",
      "Loss = 0.3276357650756836, training accuracy = 91.89111111111112\n",
      "Loss = 0.32937976717948914, training accuracy = 91.9088888888889\n",
      "Loss = 0.33033376932144165, training accuracy = 91.92444444444445\n",
      "Loss = 0.3296310007572174, training accuracy = 91.94222222222223\n",
      "Loss = 0.3315119743347168, training accuracy = 91.96222222222222\n",
      "Loss = 0.33189085125923157, training accuracy = 91.98444444444445\n",
      "Loss = 0.33470165729522705, training accuracy = 92.02888888888889\n",
      "Loss = 0.3330206573009491, training accuracy = 92.04666666666667\n",
      "Loss = 0.33616819977760315, training accuracy = 92.05555555555556\n",
      "Loss = 0.33590471744537354, training accuracy = 92.07333333333334\n",
      "Loss = 0.3385432958602905, training accuracy = 92.12222222222222\n",
      "Loss = 0.34054532647132874, training accuracy = 92.13111111111111\n",
      "Loss = 0.3374180197715759, training accuracy = 92.16444444444444\n",
      "Loss = 0.33873865008354187, training accuracy = 92.20222222222222\n",
      "Loss = 0.338453471660614, training accuracy = 92.22\n",
      "Loss = 0.3412727117538452, training accuracy = 92.24\n",
      "Loss = 0.3392704725265503, training accuracy = 92.28888888888889\n",
      "Loss = 0.34014880657196045, training accuracy = 92.28\n",
      "Loss = 0.3406108617782593, training accuracy = 92.27777777777777\n",
      "Loss = 0.3390801250934601, training accuracy = 92.31111111111112\n",
      "Loss = 0.3428133428096771, training accuracy = 92.33555555555556\n",
      "Loss = 0.34232908487319946, training accuracy = 92.3488888888889\n",
      "Loss = 0.34404513239860535, training accuracy = 92.36444444444444\n",
      "Loss = 0.3431762456893921, training accuracy = 92.39555555555556\n",
      "Loss = 0.3411481976509094, training accuracy = 92.39111111111112\n",
      "Loss = 0.3411751687526703, training accuracy = 92.44444444444444\n",
      "Loss = 0.3434702157974243, training accuracy = 92.47111111111111\n",
      "Loss = 0.34348252415657043, training accuracy = 92.46444444444444\n",
      "Loss = 0.3424522578716278, training accuracy = 92.52888888888889\n",
      "Loss = 0.3404651880264282, training accuracy = 92.51777777777778\n",
      "Loss = 0.33904120326042175, training accuracy = 92.54222222222222\n",
      "Loss = 0.3375149965286255, training accuracy = 92.56222222222222\n",
      "Loss = 0.33626067638397217, training accuracy = 92.55111111111111\n",
      "Loss = 0.33686187863349915, training accuracy = 92.56\n",
      "Loss = 0.3345325291156769, training accuracy = 92.59777777777778\n",
      "Loss = 0.33490189909935, training accuracy = 92.58444444444444\n",
      "Loss = 0.3372567594051361, training accuracy = 92.60222222222222\n",
      "Loss = 0.33918675780296326, training accuracy = 92.61111111111111\n",
      "Loss = 0.3363739848136902, training accuracy = 92.63333333333334\n",
      "Loss = 0.3353016972541809, training accuracy = 92.64\n",
      "Loss = 0.3347483277320862, training accuracy = 92.61555555555556\n",
      "Loss = 0.33350345492362976, training accuracy = 92.67555555555556\n",
      "Loss = 0.3324419856071472, training accuracy = 92.66222222222223\n",
      "Loss = 0.3313286602497101, training accuracy = 92.68222222222222\n",
      "Loss = 0.3322645425796509, training accuracy = 92.67777777777778\n",
      "Loss = 0.33123481273651123, training accuracy = 92.67333333333333\n",
      "Loss = 0.32746466994285583, training accuracy = 92.7088888888889\n",
      "Loss = 0.3289824426174164, training accuracy = 92.71333333333334\n",
      "Loss = 0.32852017879486084, training accuracy = 92.72888888888889\n",
      "Loss = 0.3283331096172333, training accuracy = 92.76666666666667\n",
      "Loss = 0.3305038511753082, training accuracy = 92.74888888888889\n",
      "Loss = 0.33010318875312805, training accuracy = 92.79555555555555\n",
      "Loss = 0.3284645974636078, training accuracy = 92.81111111111112\n",
      "Loss = 0.3298964500427246, training accuracy = 92.81777777777778\n",
      "Loss = 0.3347886800765991, training accuracy = 92.85777777777778\n",
      "Loss = 0.3298088610172272, training accuracy = 92.84444444444445\n",
      "Loss = 0.32994526624679565, training accuracy = 92.82222222222222\n",
      "Loss = 0.32745352387428284, training accuracy = 92.89333333333333\n",
      "Loss = 0.33554399013519287, training accuracy = 92.87777777777778\n",
      "Loss = 0.3294350802898407, training accuracy = 92.92444444444445\n",
      "Loss = 0.33003270626068115, training accuracy = 92.87777777777778\n",
      "Loss = 0.3273140788078308, training accuracy = 92.92222222222222\n",
      "Loss = 0.3308006823062897, training accuracy = 92.97555555555556\n",
      "Loss = 0.3300381898880005, training accuracy = 92.97111111111111\n",
      "Loss = 0.32731854915618896, training accuracy = 92.9888888888889\n",
      "Loss = 0.3202923536300659, training accuracy = 93.02444444444444\n",
      "Loss = 0.32066941261291504, training accuracy = 93.04\n",
      "Loss = 0.32562124729156494, training accuracy = 93.01555555555555\n",
      "Loss = 0.3223559856414795, training accuracy = 93.01555555555555\n",
      "Loss = 0.3202744126319885, training accuracy = 93.03555555555556\n",
      "Loss = 0.320442259311676, training accuracy = 93.08444444444444\n",
      "Loss = 0.3187426030635834, training accuracy = 93.10888888888888\n",
      "Loss = 0.3207634687423706, training accuracy = 93.1\n",
      "Loss = 0.31949329376220703, training accuracy = 93.10222222222222\n",
      "Loss = 0.3185127079486847, training accuracy = 93.11333333333333\n",
      "Loss = 0.32299745082855225, training accuracy = 93.12666666666667\n",
      "tensor(0.9305)\n"
     ]
    }
   ],
   "execution_count": 219
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
